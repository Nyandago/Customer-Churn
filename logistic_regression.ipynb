{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we have here is an exercise to try and understand how we can\n",
    "# use Machine Learning to predict whether or not a customer is about to leave your company (otherwise known as Churn). \n",
    "\n",
    "# These are the three parts of our exercise :\n",
    "# Part 1- Data Cleaning Formatting the data so that our predictive algorithm can understand it.\n",
    "# Part 2- Data Learning We give the data to our algorithm for it to learn from it, find the hidden patterns and make accurate predictions.\n",
    "# Part 3- Data Predicting We use our now trained model to make predictions on our current customers and take the corresponding action.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Pandas is the most popular library for manipulating data. Think of it as an Excel but a million times faster and more practical.\n",
    "import numpy as np # This library allows to easily carry out simple and complex mathematical operations.\n",
    "import matplotlib.pyplot as plt #Allows us to plot data, create graphs and visualize data. Perfect for your Powerpoint slides ;)\n",
    "import sklearn #The one and only. This amazing library holds all the secrets. Containing powerful algorithms packed in a single line of code, this is where the magic will happen.\n",
    "import sklearn.model_selection # more of sklearn. It is a big library, but trust me it is worth it.\n",
    "import sklearn.preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score,mean_absolute_error,mean_squared_error,precision_score,recall_score, accuracy_score,f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import random # Allows us to call random numbers, occasionally very useful.\n",
    "import pprint#Allows us to neatly display text\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "#Classifiers Algorithms\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Regression Algorithms\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "from sklearn.linear_model import BayesianRidge \n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# %pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m682.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Index(['CustomerID', 'Gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
      "       'Tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
      "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# %pip install openpyxl\n",
    "\n",
    "# Here we simly use the 'pd.read_excel' command to open the excel file.\n",
    "data=pd.read_excel('Telco_Customer_Churn.xlsx')\n",
    "\n",
    "# This allows us to look at the name of each column. Notice that now all our data is stored as the word 'data' and we can operate on it by using saying'data.(command)'\n",
    "columnnames=data.columns \n",
    "\n",
    "print(columnnames) #Displays the names of our columns so that can start to get a feel for our datasheet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
